{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data modeling with Cassandra (By using Sparkify data)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PROJECT OBJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, it will use Cassandra to store the great amount of users' activity data. This project can be seperated into five parts. The **first part** is about using python to extract data from all csv files and save into an \"overall csv file\" for further use. The **second part** is relating to design Cassandra tables based on analytics team's needs and put data in these tables. As the design philosophy in Cassandra is different than tranditional SQL database, we must develop the table based on queries the analytics teams want. Since the analytics teams gives three queries, we will create three tables for them. The **third part** is about testing. After putting data into tables, we will run the queries to test whether we can get data from Cassandra tables or not. The **fourth part** is regarding to drop table. The **fifth part** is about closing the connection with cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1. Extract data from CSV files and save in an \"overall CSV file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Process the files to create an \"overall CSV file\" that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# create dialect for following csv write            \n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "# creating a csv file called event_datafile_new and dump data in it\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2. design Cassandra tables and put data in these tables\n",
    "\n",
    "#### The image below is a screenshot of event_datafile_new.csv\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to cassandra database\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7ff368e190b8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Keyspace \"sparkifycassandra\" \n",
    "session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS sparkifycassandra \n",
    "                    WITH REPLICATION = {'class':'SimpleStrategy', 'replication_factor':1}\"\"\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the sparkifycassandra keyspace\n",
    "session.set_keyspace('sparkifycassandra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create tables bases on queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5-1. Query 1: Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table for query1\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_information_on_specific_session \"\n",
    "query = query + \"(sessionId int, \\\n",
    "                  itemInSession int, \\\n",
    "                  artist text, \\\n",
    "                  song text, \\\n",
    "                  length float,\\\n",
    "                  PRIMARY KEY (sessionId, itemInSession))\"\n",
    "session.execute(query)\n",
    "\n",
    "\n",
    "# insert data into this table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_information_on_specific_session (sessionId, \\\n",
    "                                                                   itemInSession, \\\n",
    "                                                                   artist, \\\n",
    "                                                                   song, \\\n",
    "                                                                   length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5-2. Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table for query2\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_for_specific_session_and_user\"\n",
    "query = query + \"(sessionId int, \\\n",
    "                  userId int, \\\n",
    "                  itemInSession int, \\\n",
    "                  artist text, \\\n",
    "                  song text, \\\n",
    "                  firstName text, \\\n",
    "                  lastName text, \\\n",
    "                  PRIMARY KEY ((sessionId, userid), itemInSession))\"\n",
    "session.execute(query)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# insert data into this table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_for_specific_session_and_user (sessionId, \\\n",
    "                                                                 userId, \\\n",
    "                                                                 itemInSession, \\\n",
    "                                                                 artist, \\\n",
    "                                                                 song, \\\n",
    "                                                                 firstName, \\\n",
    "                                                                 lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (int(line[8]), int(line[10]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5-3. Query 3:  Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table for query3\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_listerned_by_who \"\n",
    "query = query + \"(song text, \\\n",
    "                  userId int, \\\n",
    "                  firstName text, \\\n",
    "                  lastName text, \\\n",
    "                  PRIMARY KEY (song, userId))\"\n",
    "\n",
    "session.execute(query)\n",
    "\n",
    "\n",
    "# insert data into this table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_listerned_by_who (song, \\\n",
    "                                                    userId, \\\n",
    "                                                    firstName, \\\n",
    "                                                    lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3. test whether the data is stored successfully or nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song='Music Matters (Mark Knight Dub)', length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "# test query 1\n",
    "query = \"select artist, song, length from song_information_on_specific_session WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "rows = session.execute(query)\n",
    "for row in rows:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n"
     ]
    }
   ],
   "source": [
    "# test query 2\n",
    "query = \"select artist, song, firstname, lastname from song_for_specific_session_and_user WHERE sessionId = 182 AND userId = 10\"\n",
    "rows = session.execute(query)\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(firstname='Jacqueline', lastname='Lynch')\n",
      "Row(firstname='Tegan', lastname='Levine')\n",
      "Row(firstname='Sara', lastname='Johnson')\n"
     ]
    }
   ],
   "source": [
    "# test query 3\n",
    "query = \"select firstName, lastName from song_listerned_by_who WHERE song = 'All Hands Against His Own'\"\n",
    "rows = session.execute(query)\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4. Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7ff368e0aa90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the table which is created for query 1\n",
    "query = \"drop table song_information_on_specific_session\"\n",
    "session.execute(query)\n",
    "\n",
    "# drop the table which is created for query 2\n",
    "query = \"drop table song_for_specific_session_and_user\"\n",
    "session.execute(query)\n",
    "\n",
    "# drop the table which is created for query 3\n",
    "query = \"drop table song_listerned_by_who\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part5. Close the session and cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
